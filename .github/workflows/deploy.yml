name: Deploy Weather App to AWS EKS

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  # Job 1: Deploy base infrastructure (VPC, ECR)
  base_infrastructure:
    name: 'Deploy Base Infrastructure'
    runs-on: ubuntu-latest
    outputs:
      vpc_id: ${{ steps.outputs.outputs.vpc_id }}
      ecr_registry: ${{ steps.outputs.outputs.ecr_registry }}
      project_name: ${{ steps.outputs.outputs.project_name }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-2

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.5.0
        terraform_wrapper: false

    - name: Terraform Init
      working-directory: ./infra
      run: terraform init

    - name: Force unlock if needed
      working-directory: ./infra
      run: |
        echo "Checking for existing state locks..."
        if ! terraform plan -lock-timeout=30s &> /dev/null; then
          echo "State is locked, force unlocking..."
          terraform force-unlock -force 517d1e7f-85f8-6782-282e-04083897b0ad
        else
          echo "No lock found, proceeding..."
        fi
      continue-on-error: true

    - name: Terraform Plan - Base Infrastructure
      working-directory: ./infra
      run: terraform plan -target=module.vpc -target=module.ecr -lock-timeout=10m

    - name: Terraform Apply - Base Infrastructure (only on main branch)
      if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      working-directory: ./infra
      run: terraform apply -auto-approve -target=module.vpc -target=module.ecr -lock-timeout=10m

    - name: Get Base Infrastructure Outputs
      if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      id: outputs
      working-directory: ./infra
      run: |
        echo "vpc_id=$(terraform output -raw vpc_id)" >> $GITHUB_OUTPUT
        echo "ecr_registry=$(terraform output -raw ecr_registry_url)" >> $GITHUB_OUTPUT
        echo "project_name=$(terraform output -raw project_name)" >> $GITHUB_OUTPUT

  # Job 2: Deploy EKS cluster
  eks_infrastructure:
    name: 'Deploy EKS Cluster'
    runs-on: ubuntu-latest
    needs: base_infrastructure
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    outputs:
      cluster_name: ${{ steps.outputs.outputs.cluster_name }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-2

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.5.0
        terraform_wrapper: false

    - name: Terraform Init
      working-directory: ./infra
      run: terraform init

    - name: Terraform Plan - EKS
      working-directory: ./infra
      run: terraform plan -target=module.eks -lock-timeout=10m

    - name: Terraform Apply - EKS
      working-directory: ./infra
      run: terraform apply -auto-approve -target=module.eks -lock-timeout=10m

    - name: Get EKS Outputs
      id: outputs
      working-directory: ./infra
      run: |
        echo "cluster_name=$(terraform output -raw cluster_name)" >> $GITHUB_OUTPUT

  # Job 3: Deploy IAM roles (depends on EKS OIDC)
  iam_infrastructure:
    name: 'Deploy IAM Roles'
    runs-on: ubuntu-latest
    needs: [base_infrastructure, eks_infrastructure]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    outputs:
      alb_role_arn: ${{ steps.outputs.outputs.alb_role_arn }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-2

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.5.0
        terraform_wrapper: false

    - name: Terraform Init
      working-directory: ./infra
      run: terraform init

    - name: Terraform Plan - IAM Roles
      working-directory: ./infra
      run: terraform plan -target=module.iam -lock-timeout=10m

    - name: Terraform Apply - IAM Roles
      working-directory: ./infra
      run: terraform apply -auto-approve -target=module.iam -lock-timeout=10m

    - name: Get IAM Outputs
      id: outputs
      working-directory: ./infra
      run: |
        echo "alb_role_arn=$(terraform output -raw alb_controller_role_arn)" >> $GITHUB_OUTPUT

  # Job 4: Complete infrastructure deployment
  complete_infrastructure:
    name: 'Complete Infrastructure Deployment'
    runs-on: ubuntu-latest
    needs: [base_infrastructure, eks_infrastructure, iam_infrastructure]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-2

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.5.0
        terraform_wrapper: false

    - name: Terraform Init
      working-directory: ./infra
      run: terraform init

    - name: Final Terraform Apply - All Remaining Resources
      working-directory: ./infra
      run: |
        echo "Applying any remaining Terraform resources..."
        terraform apply -auto-approve -lock-timeout=10m
        echo "âœ… Complete infrastructure deployment finished"

  # Job 5: Build and push Docker images
  build:
    name: 'Build Docker Images'
    runs-on: ubuntu-latest
    needs: [base_infrastructure, complete_infrastructure]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-2

    - name: Setup ECR and Login
      run: |
        echo "=== Setting up ECR Registry ==="
        
        # Get AWS account ID directly
        AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
        ECR_REGISTRY="${AWS_ACCOUNT_ID}.dkr.ecr.us-east-2.amazonaws.com"
        
        echo "AWS Account ID: $AWS_ACCOUNT_ID"
        echo "ECR Registry: $ECR_REGISTRY"
        
        # Store in environment for later steps
        echo "ECR_REGISTRY=$ECR_REGISTRY" >> $GITHUB_ENV
        echo "AWS_ACCOUNT_ID=$AWS_ACCOUNT_ID" >> $GITHUB_ENV
        
        # Login to ECR
        echo "Logging into ECR..."
        aws ecr get-login-password --region us-east-2 | docker login --username AWS --password-stdin "$ECR_REGISTRY"
        echo "âœ… Successfully logged into ECR"

    - name: Set Project Name
      run: |
        PROJECT_NAME="${{ needs.base_infrastructure.outputs.project_name }}"
        if [ -z "$PROJECT_NAME" ]; then
          PROJECT_NAME="weather-forecast-microservice"
          echo "Using default project name: $PROJECT_NAME"
        else
          echo "Using project name from Terraform: $PROJECT_NAME"
        fi
        echo "PROJECT_NAME=$PROJECT_NAME" >> $GITHUB_ENV

    - name: Create ECR Repository
      run: |
        echo "Creating ECR repository if it doesn't exist..."
        aws ecr describe-repositories --repository-names "$PROJECT_NAME" --region us-east-2 || \
        aws ecr create-repository --repository-name "$PROJECT_NAME" --region us-east-2
        echo "âœ… ECR repository ready"

    - name: Build Frontend
      working-directory: ./frontend
      env:
        REACT_APP_API_URL: /api
      run: |
        echo "Building React app with API_URL=/api"
        npm install
        npm run build
        echo "âœ… Frontend built successfully"

    - name: Build and Push Frontend Image
      working-directory: ./frontend
      run: |
        FRONTEND_TAG="$ECR_REGISTRY/$PROJECT_NAME:frontend-${{ github.sha }}"
        echo "Building frontend image: $FRONTEND_TAG"
        
        docker build -t "$FRONTEND_TAG" .
        docker push "$FRONTEND_TAG"
        echo "âœ… Frontend image pushed: $FRONTEND_TAG"

    - name: Build and Push Backend Image
      working-directory: ./backend
      run: |
        BACKEND_TAG="$ECR_REGISTRY/$PROJECT_NAME:backend-${{ github.sha }}"
        echo "Building backend image: $BACKEND_TAG"
        
        docker build -t "$BACKEND_TAG" .
        docker push "$BACKEND_TAG"
        echo "âœ… Backend image pushed: $BACKEND_TAG"

  # Job 6: Deploy to Kubernetes
  deploy:
    name: 'Deploy to EKS'
    runs-on: ubuntu-latest
    needs: [base_infrastructure, eks_infrastructure, iam_infrastructure, complete_infrastructure, build]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-2

    - name: Install kubectl
      run: |
        curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
        chmod +x kubectl
        sudo mv kubectl /usr/local/bin/
        echo "âœ… kubectl installed"

    - name: Install Helm
      run: |
        curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
        echo "âœ… Helm installed"

    - name: Connect to EKS cluster
      run: |
        aws eks update-kubeconfig --region us-east-2 --name weather-forcast-application-eks
        kubectl get nodes
        echo "âœ… Connected to EKS cluster"

    - name: Setup EKS OIDC Provider
      run: |
        echo "Setting up OIDC provider for EKS cluster..."
        
        # Get the OIDC issuer URL
        OIDC_URL=$(aws eks describe-cluster --name ${{ needs.eks_infrastructure.outputs.cluster_name }} --region us-east-2 --query "cluster.identity.oidc.issuer" --output text)
        echo "OIDC URL: $OIDC_URL"
        
        # Extract the OIDC ID
        OIDC_ID=$(echo $OIDC_URL | cut -d '/' -f 5)
        echo "OIDC ID: $OIDC_ID"
        
        # Check if OIDC provider already exists
        if aws iam list-open-id-connect-providers --query "OpenIDConnectProviderList[?ends_with(Arn, ':oidc-provider/$OIDC_URL')]" --output text | grep -q "$OIDC_ID"; then
          echo "âœ… OIDC provider already exists"
        else
          echo "Creating OIDC provider..."
          
          # Get the certificate thumbprint
          THUMBPRINT=$(echo | openssl s_client -servername oidc.eks.us-east-2.amazonaws.com -showcerts -connect oidc.eks.us-east-2.amazonaws.com:443 2>&- | tac | sed -n '/-----END CERTIFICATE-----/,/-----BEGIN CERTIFICATE-----/p; /-----BEGIN CERTIFICATE-----/q' | tac | openssl x509 -fingerprint -sha1 -noout | sed 's/://g' | awk -F= '{print tolower($2)}')
          
          # Create the OIDC provider
          aws iam create-open-id-connect-provider \
            --url $OIDC_URL \
            --client-id-list sts.amazonaws.com \
            --thumbprint-list $THUMBPRINT \
            --region us-east-2 || echo "OIDC provider might already exist"
          
          echo "âœ… OIDC provider created/verified"
        fi

    - name: Install AWS Load Balancer Controller
      run: |
        echo "Installing AWS Load Balancer Controller..."
        echo "Cluster: ${{ needs.eks_infrastructure.outputs.cluster_name }}"
        echo "IAM Role: ${{ needs.iam_infrastructure.outputs.alb_role_arn }}"
        echo "VPC ID: ${{ needs.base_infrastructure.outputs.vpc_id }}"
        
        # Add Helm repo
        helm repo add eks https://aws.github.io/eks-charts
        helm repo update
        
        # Clean up any existing installation
        helm uninstall aws-load-balancer-controller -n kube-system --ignore-not-found || echo "No existing installation"
        
        # Install ALB controller with Helm managing the service account
        helm install aws-load-balancer-controller eks/aws-load-balancer-controller \
          -n kube-system \
          --set clusterName=${{ needs.eks_infrastructure.outputs.cluster_name }} \
          --set serviceAccount.create=true \
          --set serviceAccount.name=aws-load-balancer-controller \
          --set serviceAccount.annotations."eks\.amazonaws\.com/role-arn"=${{ needs.iam_infrastructure.outputs.alb_role_arn }} \
          --set region=us-east-2 \
          --set vpcId=${{ needs.base_infrastructure.outputs.vpc_id }} \
          --wait \
          --timeout=10m
        
        echo "âœ… AWS Load Balancer Controller installed"
        
        # Verify installation
        kubectl get deployment aws-load-balancer-controller -n kube-system
        kubectl rollout status deployment aws-load-balancer-controller -n kube-system --timeout=300s
        echo "âœ… ALB Controller is ready and running"

    - name: Setup ECR Registry for Kubernetes
      run: |
        # Get AWS account ID and set up ECR registry for k8s manifests
        AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
        ECR_REGISTRY="${AWS_ACCOUNT_ID}.dkr.ecr.us-east-2.amazonaws.com"
        PROJECT_NAME="${{ needs.base_infrastructure.outputs.project_name }}"
        
        if [ -z "$PROJECT_NAME" ]; then
          PROJECT_NAME="weather-forecast-microservice"
        fi
        
        echo "ECR_REGISTRY=$ECR_REGISTRY" >> $GITHUB_ENV
        echo "PROJECT_NAME=$PROJECT_NAME" >> $GITHUB_ENV

    - name: Update secret with API key
      run: |
        echo "Updating secret with API key..."
        
        # Base64 encode the API key
        ENCODED_API_KEY=$(echo -n "${{ secrets.OPENWEATHER_API_KEY }}" | base64)
        
        # Replace placeholder in secret.yaml
        if [ -f "k8s/secret.yaml" ]; then
          sed -i "s|OPENWEATHER_API_KEY_BASE64_PLACEHOLDER|$ENCODED_API_KEY|g" k8s/secret.yaml
          echo "âœ… Secret updated with API key"
        else
          echo "âš ï¸ k8s/secret.yaml not found"
        fi

    - name: Update image tags in manifests
      run: |
        echo "Updating image tags in manifests..."
        
        # Replace image placeholders with actual ECR image tags
        sed -i "s|IMAGE_PLACEHOLDER_FRONTEND|$ECR_REGISTRY/$PROJECT_NAME:frontend-${{ github.sha }}|g" k8s/frontend-deployment.yaml
        sed -i "s|IMAGE_PLACEHOLDER_BACKEND|$ECR_REGISTRY/$PROJECT_NAME:backend-${{ github.sha }}|g" k8s/backend-deployment.yaml
        
        echo "Frontend image: $ECR_REGISTRY/$PROJECT_NAME:frontend-${{ github.sha }}"
        echo "Backend image: $ECR_REGISTRY/$PROJECT_NAME:backend-${{ github.sha }}"
        echo "âœ… Image tags updated"

    - name: Deploy Kubernetes resources with retry
      run: |
        echo "Deploying Kubernetes resources with retry logic..."
        
        # Function to deploy with retry
        deploy_with_retry() {
          local max_attempts=3
          local attempt=1
          
          while [ $attempt -le $max_attempts ]; do
            echo "ğŸš€ Deployment attempt $attempt of $max_attempts"
            
            if kubectl apply -f k8s/ 2>&1 | tee /tmp/kubectl_output.log; then
              echo "âœ… Kubernetes resources deployed successfully on attempt $attempt"
              return 0
            else
              echo "âŒ Deployment attempt $attempt failed"
              
              # Show what failed
              cat /tmp/kubectl_output.log
              
              # If namespace doesn't exist, create it first
              if grep -q "namespace.*not found" /tmp/kubectl_output.log; then
                echo "ğŸ”§ Namespace issue detected, trying to create namespace first..."
                kubectl create namespace prod-team --dry-run=client -o yaml | kubectl apply -f - || true
                sleep 5
              fi
              
              # Wait before retry
              if [ $attempt -lt $max_attempts ]; then
                echo "â³ Waiting 10 seconds before retry..."
                sleep 10
              fi
            fi
            
            ((attempt++))
          done
          
          echo "âŒ All deployment attempts failed"
          return 1
        }
        
        # Try ordered deployment first
        echo "ğŸ“‹ Trying ordered deployment..."
        
        # 1. Deploy namespace first (if exists)
        if [ -f "k8s/namespace.yaml" ]; then
          kubectl apply -f k8s/namespace.yaml || echo "âš ï¸ Namespace deployment failed, continuing..."
          sleep 2
        fi
        
        # 2. Deploy secrets (if exists)
        if [ -f "k8s/secret.yaml" ]; then
          kubectl apply -f k8s/secret.yaml || echo "âš ï¸ Secret deployment failed, continuing..."
          sleep 2
        fi
        
        # 3. Deploy everything else
        deploy_with_retry
        
        echo "âœ… Kubernetes deployment completed"

    - name: Wait for deployments
      run: |
        echo "Waiting for deployments to be ready..."
        
        # Wait with timeout and retry logic
        wait_for_deployment() {
          local deployment_name=$1
          local max_attempts=3
          local attempt=1
          
          while [ $attempt -le $max_attempts ]; do
            echo "â³ Waiting for $deployment_name (attempt $attempt/$max_attempts)..."
            
            if kubectl rollout status deployment/$deployment_name -n prod-team --timeout=300s; then
              echo "âœ… $deployment_name is ready"
              return 0
            else
              echo "âŒ $deployment_name failed to become ready on attempt $attempt"
              
              # Show pod status for debugging
              kubectl get pods -n prod-team -l app=$deployment_name || true
              kubectl describe deployment $deployment_name -n prod-team || true
              
              if [ $attempt -lt $max_attempts ]; then
                echo "ğŸ”„ Restarting $deployment_name deployment..."
                kubectl rollout restart deployment/$deployment_name -n prod-team || true
                sleep 30
              fi
            fi
            
            ((attempt++))
          done
          
          echo "âŒ $deployment_name failed to become ready after all attempts"
          return 1
        }
        
        # Wait for both deployments
        wait_for_deployment "weather-frontend"
        wait_for_deployment "weather-backend"
        
        echo "âœ… All deployments are ready"

    - name: Get application URL
      run: |
        echo "Waiting for load balancer to be ready..."
        sleep 60
        
        ALB_URL=$(kubectl get ingress weather-app-ingress -n prod-team -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "")
        
        if [ -n "$ALB_URL" ]; then
          echo "ğŸš€ Application deployed successfully!"
          echo "ğŸ“± Frontend URL: http://$ALB_URL"
          echo "ğŸ”§ API Health: http://$ALB_URL/api/health"
          echo "ğŸŒ¤ï¸  Weather API: http://$ALB_URL/api/weather/London"
        else
          echo "âš ï¸ Load balancer not ready yet. Check ingress status manually:"
          kubectl get ingress -n prod-team || true
          kubectl describe ingress weather-app-ingress -n prod-team || true
        fi

    - name: Run health checks with retry
      run: |
        echo "Running health checks with retry..."
        
        # Function to check endpoint with retry
        check_endpoint_with_retry() {
          local url=$1
          local name=$2
          local max_attempts=5
          local attempt=1
          
          while [ $attempt -le $max_attempts ]; do
            echo "ğŸ” Checking $name (attempt $attempt/$max_attempts): $url"
            
            if curl -f -s --max-time 10 "$url" > /dev/null; then
              echo "âœ… $name check passed"
              return 0
            else
              echo "âŒ $name check failed on attempt $attempt"
              
              if [ $attempt -lt $max_attempts ]; then
                echo "â³ Waiting 30 seconds before retry..."
                sleep 30
              fi
            fi
            
            ((attempt++))
          done
          
          echo "âŒ $name check failed after all attempts"
          return 1
        }
        
        # Get ALB URL with retry
        for i in {1..5}; do
          ALB_URL=$(kubectl get ingress weather-app-ingress -n prod-team -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "")
          
          if [ -n "$ALB_URL" ]; then
            echo "âœ… Found ALB URL: $ALB_URL"
            break
          else
            echo "â³ Waiting for ALB URL (attempt $i/5)..."
            sleep 30
          fi
        done
        
        if [ -n "$ALB_URL" ]; then
          echo "ğŸ§ª Running health checks..."
          
          # Test API health
          check_endpoint_with_retry "http://$ALB_URL/api/health" "API Health"
          
          # Test weather endpoint
          check_endpoint_with_retry "http://$ALB_URL/api/weather/London" "Weather API"
          
          echo "ğŸ‰ All health checks completed! Your app should be live at:"
          echo "ğŸ“± Frontend: http://$ALB_URL"
          echo "ğŸ”§ API Health: http://$ALB_URL/api/health"
          echo "ğŸŒ¤ï¸  Weather API: http://$ALB_URL/api/weather/London"
        else
          echo "âš ï¸ Could not get ALB URL, skipping health checks"
          echo "ğŸ” Manual check commands:"
          echo "kubectl get ingress -n prod-team"
          echo "kubectl get pods -n prod-team"
          echo "kubectl get services -n prod-team"
        fi
